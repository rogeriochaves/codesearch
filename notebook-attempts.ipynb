{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, PretrainedConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65b7dc1293b46eda479836d46a3750d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/720 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e424babbb848e6a2c5e8793ce77d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49ec0b4109a436d87a8d4ed538a1413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e4826b35384ade95a28db78d67dfe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/45.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f56459ef66d46d490808b9a003fe2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/358 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611da437c52244bd8010118dee91e139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/177 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4adb85fff22f45d89ed1bfc6e1cb0ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/510M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(\"xlnet-base-cased\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/CodeGPT-small-py-adaptedGPT2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/CodeGPT-small-py-adaptedGPT2\", pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# config = PretrainedConfig(model=\"distilgpt2\", pad_token_id=50256)\n",
    "# text_generator = pipeline(\"text-generation\", model=\"distilgpt2\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pandas.DataFrame.groupby¶ ... Group DataFrame using a mapper or by a Series of columns. A groupby operation involves some combination of splitting the object, ...',\n",
       " 'pandas.DataFrame.groupby')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_samples():\n",
    "    with open(\"samples.txt\") as f:\n",
    "        content = f.readlines()\n",
    "    data = {\n",
    "        \"input\": [],\n",
    "        \"output\": []\n",
    "    }\n",
    "    last = \"output\"\n",
    "    for i, line in enumerate(content):\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "        if line.startswith(\"Input:\"):\n",
    "            if last != \"output\":\n",
    "                raise Exception(\"Input on line %i does not match a previous output\" % i)\n",
    "            last = \"input\"\n",
    "        elif line.startswith(\"Output:\"):\n",
    "            if last != \"input\":\n",
    "                raise Exception(\"Input on line %i does not match a previous output\" % i)\n",
    "            last = \"output\"\n",
    "        else:\n",
    "            data[last].append(line.strip())\n",
    "    \n",
    "    return list(zip(data[\"input\"], data[\"output\"]))\n",
    "samples = read_samples()\n",
    "samples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: For DataFrame objects, a string indicating either a column name or an index level name to be used to group. df.groupby('A') is just syntactic sugar for df.groupby(df\n",
      "Output: df.groupby('A') df.groupby(df\n",
      "\n",
      "Input: pandas.DataFrame.groupby¶ ... Group DataFrame using a mapper or by a Series of columns. A groupby operation involves some combination of splitting the object, ...\n",
      "Output: pandas.DataFrame.groupby\n",
      "\n",
      "Input: In this tutorial, you'll learn how to work adeptly with the Pandas GroupBy facility while mastering ways to manipulate, transform, and summarize data. You'll work ...\n",
      "Output: None\n",
      "\n",
      "Input: Pandas dataframe.groupby() function is used to split the data into groups based on some criteria. pandas objects can be split on any of their axes.\n",
      "Output: dataframe.groupby()\n",
      "\n",
      "Input: There's probably a slicker way to do this but this works: def reindex_by_date(df): dates = pd.date_range(df.index.min(), df.index.max()) return\n",
      "Output: def reindex_by_date(df): dates = pd.date_range(df.index.min(), df.index.max()) return\n",
      "\n",
      "Input: DataFrame.groupby · pandas. ... Create a new index and reindex the dataframe. ... df.reindex(new_index, fill_value=0) http_status response_time Safari 404\n",
      "Output: DataFrame.groupby df.reindex(new_index, fill_value=0)\n",
      "\n",
      "Input: class CancerDataEntity(Model): age = columns. Text(primary_key=True) gender = columns. Text(primary_key=True) cancer = columns.\n",
      "Output: class CancerDataEntity(Model): age = columns. Text(primary_key=True) gender = columns. Text(primary_key=True) cancer = columns.\n",
      "\n",
      "Input: Sort of a combination of ayhan's suggestion and what you seem to want -- you can add a method to your Person class that transforms it into\n",
      "Output: None\n",
      "\n",
      "Input: You can refer the following code that leads to the desired result: variables = arr[0].keys(). df = pd.DataFrame([[getattr(i,k) for k in variables] for i ...\n",
      "Output: variables = arr[0].keys(). df = pd.DataFrame([[getattr(i,k) for k in variables] for i\n",
      "\n",
      "Input: To replace content in a file, you must search for the particular file string. The 'sed' command is used to replace any string in a file using a bash script. This command can be used in various ways to replace the content of a file in bash. The 'awk' command can also be used to replace the string in a file.\n",
      "Output: None\n",
      "\n",
      "Input: The easiest way is to use sed (or perl): sed -i -e 's/abc/XYZ/g' /tmp/file.txt. Which will invoke sed to do an in-place edit due to the -i option\n",
      "Output: sed -i -e 's/abc/XYZ/g' /tmp/file.txt\n",
      "\n",
      "Input: The procedure to change the text in files under Linux/Unix using sed: Use Stream EDitor (sed) as follows: sed -i 's/old-text/new-text/g' input. The s is the substitute command of sed for find and replace. It tells sed to find all occurrences of 'old-text' and replace with 'new-text' in a file named input.\n",
      "Output: sed -i 's/old-text/new-text/g'\n",
      "\n",
      "Input: Why dict.get(key) instead of dict[key]? - Stack Overflow Return the value for key if key is in the dictionary, else default. ... I will give a practical example in scraping web data using python, a lot of the ...\n",
      "Output: dict.get(key) dict[key]\n",
      "\n",
      "Input: Python dictionary get() Method Python dictionary method get() returns a value for the given key. If key is not available then returns default value None.\n",
      "Output: get() get()\n",
      "\n",
      "Input: What is the best way to filter a Java Collection? - Stack Overflow Java 8 (2014) solves this problem using streams and lambdas in one line of code: List<Person> beerDrinkers = persons.stream() .filter(p -> p.\n",
      "Output: List<Person> beerDrinkers = persons.stream() .filter(p -> p.\n",
      "\n",
      "Input: How to filter a list in Java - ZetCode The CollectionUtils. filter() method filters the result list with the given predicate. This is the output of the example. In this tutorial, we have used six different ways to filter a list in Java.\n",
      "Output: CollectionUtils. filter()\n",
      "\n",
      "Input: Java Stream Filter with Lambda Expression | Baeldung A common use case of the filter() method is processing collections. Let's make a list of customers with more than 100 points. To do that, we can ...\n",
      "Output: filter()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_context(samples):\n",
    "    context = \"\"\n",
    "    for (input_, output) in samples:\n",
    "        context += \"Input: \" + input_ + \"\\n\"\n",
    "        context += \"Output: \" + output + \"\\n\"\n",
    "        context += \"\\n\"\n",
    "    return context\n",
    "print(build_context(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: type is \"list\". For example: if an int, you can simply give \"int\n",
      "1: d.Series([[\"i_id1\", \"i_id2\"]])\n",
      "2:  : 1}**, 'gender' : 2, 'cant'\n",
      "3: tr(item,k)] for item in item} | cat for item in item\n",
      "4: p.arange(df.shape[0], dtype=int) \"\"\" #\n"
     ]
    }
   ],
   "source": [
    "PADDING_TEXT = build_context(samples[0:10])\n",
    "\n",
    "prompt = r\"\"\"Input: Series. For data-only list. By passing a list type object to the first argument of each constructor pandas.DataFrame() and\n",
    "Output: \"\"\"\n",
    "\n",
    "inputs = tokenizer.encode(PADDING_TEXT + prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_length=len(inputs[0]) + 20, do_sample=True, num_return_sequences=5)\n",
    "\n",
    "prompt_length = len(tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False))\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, output in enumerate(outputs):\n",
    "    generated = tokenizer.decode(output)[prompt_length:]\n",
    "    print(\"{}: {}\".format(i, generated))\n",
    "\n",
    "# print(text_generator(PADDING_TEXT + prompt, max_length=len(PADDING_TEXT + prompt) + 50, do_sample=False))\n",
    "# %time print(text_generator(PADDING_TEXT + prompt, max_length=1024, truncation=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The piece of in \"For DataFrame objects, a string indicating either a column name or an index level name to be used to group. df.groupby('A') is just syntactic sugar for df.groupby(df\" is df.groupby('A') df.groupby(df\n",
      "\n",
      "The piece of in \"pandas.DataFrame.groupby¶ ... Group DataFrame using a mapper or by a Series of columns. A groupby operation involves some combination of splitting the object, ...\" is pandas.DataFrame.groupby\n",
      "\n",
      "The piece of in \"In this tutorial, you'll learn how to work adeptly with the Pandas GroupBy facility while mastering ways to manipulate, transform, and summarize data. You'll work ...\" is None\n",
      "\n",
      "The piece of in \"Pandas dataframe.groupby() function is used to split the data into groups based on some criteria. pandas objects can be split on any of their axes.\" is dataframe.groupby()\n",
      "\n",
      "The piece of in \"There's probably a slicker way to do this but this works: def reindex_by_date(df): dates = pd.date_range(df.index.min(), df.index.max()) return\" is def reindex_by_date(df): dates = pd.date_range(df.index.min(), df.index.max()) return\n",
      "\n",
      "The piece of in \"DataFrame.groupby · pandas. ... Create a new index and reindex the dataframe. ... df.reindex(new_index, fill_value=0) http_status response_time Safari 404\" is DataFrame.groupby df.reindex(new_index, fill_value=0)\n",
      "\n",
      "The piece of in \"class CancerDataEntity(Model): age = columns. Text(primary_key=True) gender = columns. Text(primary_key=True) cancer = columns.\" is class CancerDataEntity(Model): age = columns. Text(primary_key=True) gender = columns. Text(primary_key=True) cancer = columns.\n",
      "\n",
      "The piece of in \"Sort of a combination of ayhan's suggestion and what you seem to want -- you can add a method to your Person class that transforms it into\" is None\n",
      "\n",
      "The piece of in \"You can refer the following code that leads to the desired result: variables = arr[0].keys(). df = pd.DataFrame([[getattr(i,k) for k in variables] for i ...\" is variables = arr[0].keys(). df = pd.DataFrame([[getattr(i,k) for k in variables] for i\n",
      "\n",
      "The piece of in \"To replace content in a file, you must search for the particular file string. The 'sed' command is used to replace any string in a file using a bash script. This command can be used in various ways to replace the content of a file in bash. The 'awk' command can also be used to replace the string in a file.\" is None\n",
      "\n",
      "The piece of in \"The easiest way is to use sed (or perl): sed -i -e 's/abc/XYZ/g' /tmp/file.txt. Which will invoke sed to do an in-place edit due to the -i option\" is sed -i -e 's/abc/XYZ/g' /tmp/file.txt\n",
      "\n",
      "The piece of in \"The procedure to change the text in files under Linux/Unix using sed: Use Stream EDitor (sed) as follows: sed -i 's/old-text/new-text/g' input. The s is the substitute command of sed for find and replace. It tells sed to find all occurrences of 'old-text' and replace with 'new-text' in a file named input.\" is sed -i 's/old-text/new-text/g'\n",
      "\n",
      "The piece of in \"Why dict.get(key) instead of dict[key]? - Stack Overflow Return the value for key if key is in the dictionary, else default. ... I will give a practical example in scraping web data using python, a lot of the ...\" is dict.get(key) dict[key]\n",
      "\n",
      "The piece of in \"Python dictionary get() Method Python dictionary method get() returns a value for the given key. If key is not available then returns default value None.\" is get() get()\n",
      "\n",
      "The piece of in \"What is the best way to filter a Java Collection? - Stack Overflow Java 8 (2014) solves this problem using streams and lambdas in one line of code: List<Person> beerDrinkers = persons.stream() .filter(p -> p.\" is List<Person> beerDrinkers = persons.stream() .filter(p -> p.\n",
      "\n",
      "The piece of in \"How to filter a list in Java - ZetCode The CollectionUtils. filter() method filters the result list with the given predicate. This is the output of the example. In this tutorial, we have used six different ways to filter a list in Java.\" is CollectionUtils. filter()\n",
      "\n",
      "The piece of in \"Java Stream Filter with Lambda Expression | Baeldung A common use case of the filter() method is processing collections. Let's make a list of customers with more than 100 points. To do that, we can ...\" is filter()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_questions_context(samples):\n",
    "    context = \"\"\n",
    "    for (input_, output) in samples:\n",
    "        context += \"The piece of in \\\"\" + input_ + \"\\\" is \" + output + \"\\n\"\n",
    "        context += \"\\n\"\n",
    "    return context\n",
    "print(build_questions_context(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.24871328473091125,\n",
       " 'start': 3368,\n",
       " 'end': 3418,\n",
       " 'answer': '\"What is the best way to filter a Java Collection?'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = nlp(\n",
    "    question=\"What is the piece of code in \\\"Series. For data-only list. By passing a list type object to the first argument of each constructor pandas.DataFrame().foo() and\\\"?\",\n",
    "    context=build_questions_context(samples)\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rchaves/.pyenv/versions/3.7.8/lib/python3.7/site-packages/transformers/models/auto/modeling_auto.py:762: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd9d0c5c6854af0a3d34ee69f881057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base-mlm\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"microsoft/codebert-base-mlm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': \"Input: For DataFrame objects, a string indicating either a column name or an index level name to be used to group. df.groupby('A') is just syntactic sugar for df.groupby(df\\nOutput: df.groupby('A') df.groupby(df\\n\\nInput: Series. For data-only list. By passing a list type object to the first argument of each constructor pandas.DataFrame() and\\nOutput: List\", 'score': 0.40711578726768494, 'token': 9527, 'token_str': ' List'}\n",
      "{'sequence': \"Input: For DataFrame objects, a string indicating either a column name or an index level name to be used to group. df.groupby('A') is just syntactic sugar for df.groupby(df\\nOutput: df.groupby('A') df.groupby(df\\n\\nInput: Series. For data-only list. By passing a list type object to the first argument of each constructor pandas.DataFrame() and\\nOutput: Series\", 'score': 0.22264915704727173, 'token': 3265, 'token_str': ' Series'}\n",
      "{'sequence': \"Input: For DataFrame objects, a string indicating either a column name or an index level name to be used to group. df.groupby('A') is just syntactic sugar for df.groupby(df\\nOutput: df.groupby('A') df.groupby(df\\n\\nInput: Series. For data-only list. By passing a list type object to the first argument of each constructor pandas.DataFrame() and\\nOutput: list\", 'score': 0.14658795297145844, 'token': 889, 'token_str': ' list'}\n",
      "{'sequence': \"Input: For DataFrame objects, a string indicating either a column name or an index level name to be used to group. df.groupby('A') is just syntactic sugar for df.groupby(df\\nOutput: df.groupby('A') df.groupby(df\\n\\nInput: Series. For data-only list. By passing a list type object to the first argument of each constructor pandas.DataFrame() and\\nOutput: Data\", 'score': 0.04174148291349411, 'token': 5423, 'token_str': ' Data'}\n",
      "{'sequence': \"Input: For DataFrame objects, a string indicating either a column name or an index level name to be used to group. df.groupby('A') is just syntactic sugar for df.groupby(df\\nOutput: df.groupby('A') df.groupby(df\\n\\nInput: Series. For data-only list. By passing a list type object to the first argument of each constructor pandas.DataFrame() and\\nOutput: Array\", 'score': 0.021204574033617973, 'token': 42719, 'token_str': ' Array'}\n"
     ]
    }
   ],
   "source": [
    "code_example = build_context(samples[0:1]) + prompt + \"<mask>\"\n",
    "fill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
    "\n",
    "outputs = fill_mask(code_example)\n",
    "print(\"\\n\".join([ str(x) for x in outputs ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd82967e6696465c8e0130dc159cb5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce6239ab2ad443a994c668a96464f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623506f1390e49b9b157a0262376693f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8714da0d66846179aaaf092bf0e94f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b89b2f3b7934746bb6f558e3c863bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b14f49092e48cf831587f10679f049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"ner\", model=\"mrm8488/codebert-base-finetuned-stackoverflow-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 240 ms, sys: 8.99 ms, total: 249 ms\n",
      "Wall time: 259 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'word': 'Ġsed',\n",
       "  'score': 0.7651958465576172,\n",
       "  'entity': 'B-Code_Block',\n",
       "  'index': 7,\n",
       "  'start': 26,\n",
       "  'end': 29},\n",
       " {'word': 'Ġperl',\n",
       "  'score': 0.9975582361221313,\n",
       "  'entity': 'B-Language',\n",
       "  'index': 10,\n",
       "  'start': 34,\n",
       "  'end': 38},\n",
       " {'word': 'Ġsed',\n",
       "  'score': 0.9983819723129272,\n",
       "  'entity': 'B-Code_Block',\n",
       "  'index': 12,\n",
       "  'start': 41,\n",
       "  'end': 44},\n",
       " {'word': 'Ġ-',\n",
       "  'score': 0.9970406293869019,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 13,\n",
       "  'start': 45,\n",
       "  'end': 46},\n",
       " {'word': 'i',\n",
       "  'score': 0.997124195098877,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 14,\n",
       "  'start': 46,\n",
       "  'end': 47},\n",
       " {'word': 'Ġ-',\n",
       "  'score': 0.997551679611206,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 15,\n",
       "  'start': 48,\n",
       "  'end': 49},\n",
       " {'word': 'e',\n",
       "  'score': 0.9970588684082031,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 16,\n",
       "  'start': 49,\n",
       "  'end': 50},\n",
       " {'word': \"Ġ'\",\n",
       "  'score': 0.9104116559028625,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 17,\n",
       "  'start': 51,\n",
       "  'end': 52},\n",
       " {'word': 's',\n",
       "  'score': 0.988348126411438,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 18,\n",
       "  'start': 52,\n",
       "  'end': 53},\n",
       " {'word': '/',\n",
       "  'score': 0.9880527257919312,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 19,\n",
       "  'start': 53,\n",
       "  'end': 54},\n",
       " {'word': 'abc',\n",
       "  'score': 0.9902641177177429,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 20,\n",
       "  'start': 54,\n",
       "  'end': 57},\n",
       " {'word': '/',\n",
       "  'score': 0.9878599047660828,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 21,\n",
       "  'start': 57,\n",
       "  'end': 58},\n",
       " {'word': 'XY',\n",
       "  'score': 0.9924663305282593,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 22,\n",
       "  'start': 58,\n",
       "  'end': 60},\n",
       " {'word': 'Z',\n",
       "  'score': 0.9898877143859863,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 23,\n",
       "  'start': 60,\n",
       "  'end': 61},\n",
       " {'word': '/',\n",
       "  'score': 0.9895458817481995,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 24,\n",
       "  'start': 61,\n",
       "  'end': 62},\n",
       " {'word': 'g',\n",
       "  'score': 0.9925737380981445,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 25,\n",
       "  'start': 62,\n",
       "  'end': 63},\n",
       " {'word': \"'\",\n",
       "  'score': 0.9920398592948914,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 26,\n",
       "  'start': 63,\n",
       "  'end': 64},\n",
       " {'word': 'Ġ/',\n",
       "  'score': 0.6551393866539001,\n",
       "  'entity': 'B-File_Name',\n",
       "  'index': 27,\n",
       "  'start': 65,\n",
       "  'end': 66},\n",
       " {'word': 'tmp',\n",
       "  'score': 0.9585043787956238,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 28,\n",
       "  'start': 66,\n",
       "  'end': 69},\n",
       " {'word': '/',\n",
       "  'score': 0.9341182112693787,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 29,\n",
       "  'start': 69,\n",
       "  'end': 70},\n",
       " {'word': 'file',\n",
       "  'score': 0.946744978427887,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 30,\n",
       "  'start': 70,\n",
       "  'end': 74},\n",
       " {'word': '.',\n",
       "  'score': 0.9024456143379211,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 31,\n",
       "  'start': 74,\n",
       "  'end': 75},\n",
       " {'word': 'txt',\n",
       "  'score': 0.8170293569564819,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 32,\n",
       "  'start': 75,\n",
       "  'end': 78},\n",
       " {'word': 'Ġsed',\n",
       "  'score': 0.9917990565299988,\n",
       "  'entity': 'B-Code_Block',\n",
       "  'index': 37,\n",
       "  'start': 98,\n",
       "  'end': 101},\n",
       " {'word': 'Ġ-',\n",
       "  'score': 0.9980557560920715,\n",
       "  'entity': 'B-Code_Block',\n",
       "  'index': 48,\n",
       "  'start': 136,\n",
       "  'end': 137},\n",
       " {'word': 'i',\n",
       "  'score': 0.9512431025505066,\n",
       "  'entity': 'I-Code_Block',\n",
       "  'index': 49,\n",
       "  'start': 137,\n",
       "  'end': 138}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"The easiest way is to use sed (or perl): sed -i -e 's/abc/XYZ/g' /tmp/file.txt. Which will invoke sed to do an in-place edit due to the -i option\"\n",
    "\n",
    "%time nlp(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
